{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOB53xaLTPAeC8jh86ccAg8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vzYKC9TmUVko"},"outputs":[],"source":["%%capture\n","!pip install datasets transformers accelerate\n","!pip install optuna\n","!apt install git-lfs\n","!pip install -q kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cdaa2fda962842d99ce1601fab4fe9be","be62d5e64a1f457eba2594f1d9158558","7cd540f29cae47d9b71d152c59833ff7","cdfe30d10a404ae4945d5d1102d0285c","483e734608cd423bac8de6d6a8b618b1","1d869975e38842e49157ce704496b25f","cdf736eecc7f4bdc8567635246d584c5","16c2bbd0a8ad445e944c25c944d6c056","25bdc12d96264dd49de5475cbe434c18","2e91bc8c040a40e88bf5571a8a898d61","183590f3bed645eb99b63d200cfb0c77","07179f9d8bb24c7cab6d0bcd9a6b91cc","0748701177834fa8a41a0b2d75faafe0","2ad7a25928064002af64fd8524e16de3","264729dc5d4449eba2fe758f6382712c","099ba0f9b24943eaadccbd902ee2bf8e","d58cdef47c86496d978a8c58e7030049","29ae674ec3b44571ac5835c71a32feac","678b95bd6d9e4c959b6e9d6dd563ce34","5a05339c392d4478a28f0a1c56ec626b","dedb23a6082948ec8afdbadb1488a9cc","ec0e1a841fc8434eb43389350bd87032","d28b6725c9be42d58d2536d94577a8c3","75da4a88d87b4d4a85cfa9b73d576738","858f33e96b05456582889ab55a65e6ba","db4a9621383d45e3bd6258ebd52dca68","feecae0c46f04d2c8a191de98ba0088b","b08d0cce261249f6973e5f7e27f51130","6162becf3af345cfa66d6c6037cc9de2"]},"id":"J8BGqwm6yttw","outputId":"52dce80c-54f9-431d-b649-6e4fbdb8ffe8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdaa2fda962842d99ce1601fab4fe9be"}},"metadata":{}}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"vNnhw76Vy4Id"},"outputs":[],"source":["#@title Global Params\n","base_model = \"AIMH/mental-bert-base-cased\" #@param {type:\"string\"}\n","path_to_data = \"/content/drive/MyDrive/Data/merged_data.csv\" # @param [\"/content/drive/MyDrive/Data/Filtered-Mental-Health-Twitter.csv\", \"/content/drive/MyDrive/Data/data.csv\"] {allow-input: true}\n","repo_name = \"BERTForDetectingDepression-Twitter2020\" # @param [\"BERTForDetectingDepression-Twitter2015\", \"BERTForDetectingDepression-Twitter2020\"] {allow-input: true}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["ce8a312b63dc405fa5d9c09db65fee04","5c8f7db25a574ea9858198017cf97b6a","3f8e9597fa2f4892a3e234aeb79a1583","73852e944a9d4ac2af4794f1b2df1b99","9190390c55ee4cde869ebf1b7e3572ff","4977b0d7d48b4027a1124dbf33a7aed8","9f81b40795594bcb9dd92f95c5ae5a7c","2ec5d07f4d3541ecbb674415bdb36f0c","d660bd40eb174018b80d2a887affa236","f0f8138183f2405490b6a111e6190c5d","6f68ea3605e04fa4afadd385f0fd80b8"]},"id":"fDa5jQrs0ehU","outputId":"966fcd7b-f248-4f5b-879f-56a7236bc396"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce8a312b63dc405fa5d9c09db65fee04"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'user_id': 1306322067395096584, 'post_text': 'im one more heartbreak away from posting nba youngboy quotes on my story. https://t.co/YWd9ey899e. idk why i keep expecting not to get my feelings hurt🧏🏾\\u200d♀️. my asl teacher is buggin....i hate this bitch. go follow ma managa😆 @DaddyIanHawke. i want chipotle. NAE NAE😁🙏🏾 https://t.co/VamisqFnLU. down ATROCIOUS. https://t.co/ElscVi6Foj. there are so many things i just cant wrap my head around rn like 🤔🤔. arent vegans just glorified herbivores?. i don’t even know why i try anymore. THEODORE WHAT THE FUCK BRO. im so sad idk why i cause situations knowing that im gonna get my feelings hurt😕🤟🏾‼️. @dfw_ken no☺️. THATS NOT ME https://t.co/9BV47JwSxP. @dfw_ken sigh😟. someone tell @hbk_chelsea dat im not interested😐. @Vanessa23931706 PLEASEEHKDDJDK WE WILL BE FRIENDS W YOU. that was the end of the tweet. nothing else comes after https://t.co/9aS5slV2dP. i’m at my limit🙅🏾\\u200d♀️. i would express my emotions but i think im going to refrain for awhile...or forever😂😂😂🤗🤗🤗😁. why do yall follow me? i dont tweet anything interesting on here😐🗣‼️. i think im being guilt tripped lol. idk how to express emotions properly so i post songs on my story and hope people pick up on what im trying to say👩🏾\\u200d🦯👩🏾\\u200d🦯👩🏾\\u200d🦯. super rich kids by frank ocean just makes me wanna get up and bust a mf move🕺🏾. WHY ARE PEOPLE ON TIKTOK ASKING IF THEY’RE AVERAGE, ABOVE AVERAGE OR UGLY??!!? im about to start saying ugly to humble them cus this is ridiculous🧏🏾\\u200d♀️. THEY FOUND MY TWEETS🗣🗣🗣🗣EVERYONE RETREAT🗣🗣🗣🗣. all i know how to do is put myself in situations where my feelings get hurt😂😂😂😂😂😂😂😂😂😂. do yall actually have people that like yall back or does that only happen in dreams?. hey lol. i feel violent🤔. this you? https://t.co/XU6dm6rtAg https://t.co/CnKiidfBvl. @Vanessa23931706 A LOT OF US ARE FRIENDS IRL DJDKFJDK. should i eat some ice cream?🤔. some people don’t know how to apologize without guilt tripping...literally just apologize normally or shut the fuck up. if you dont get yo grown ass up and put some food on that plate..... @LadyInTheLakee dont know how to feel about this reply....at all. after i finish eating my sweet tart ropes, imma kms☺️. my asl teacher is a bitch.... if you answer yes.....why?. i just got verbally assaulted on minecraft 😕. STREAM VANISH BY GIVEON🗣🗣. ok shut the fuck up https://t.co/ABkX3GQynu. nicotine should be illegal.... people hate on kpop so much like it isnt just mainstream american pop in a different language😐 the fandoms are a different issue, but nothing wrong with the music itself !. update: sweet tart ropes made my stomach hurt😕 https://t.co/pu7slzQj89. I DONT THINK YALL UNDERSTAND HOW MF EXCITED I AM #excusemeiloveyou https://t.co/woiHO0AVxk. not that google services are down so i dont have school today???. i hate when BITCHES🗣. stream she by dodie :/. im in distress. proof? https://t.co/Um6zHuvNnL. i feel sue of side all😕🤟🏾 https://t.co/auMSTmwmrG. someone date me pls. me going to turn off snap and message notifications so i cant get anymore hurt: 🏃🏾\\u200d♀️💨. im hungry. i hate the internet https://t.co/pUIn9aLJhL. ab to start calling white people “hueless crayons”. gonna show this to my mother https://t.co/wceGwaZm3y. .@LILUZIVERT drop dolly on apple music🙏🏾🙏🏾🙏🏾🙏🏾i cant keep going to soundcloud. gm guys! gonna tweet all day and not talk to anyone😩🤟🏾 https://t.co/QqXmAonBYJ. i literally cant keep doing this anymore😂🙏🏾. my thumb hurts. im sorry😕😕😕😕 https://t.co/jtv4IC90oI. i literally cant win....pls. .@quenblackwell follow me and ill date you😩😩😩😩🤟🏾. its honestly so sad how i convinced myself that i was ugly because i went to a majority white school.... .@dfw_ken HDKDDJKDFJ PLS STOP REPLYING “hey” TO MY TWEETS. this is so unbecoming.... i think my friends are replacing me🧏🏾\\u200d♀️. do u want me or not? you holding up the line. 😐. this aint a race but i still take second place🏃🏾\\u200d♀️💨. @itsMARIAstfu twinsies😁🤟🏾. no😁 https://t.co/r5u3Sn6vv6. @dfw_ken what this mean🧏🏾\\u200d♀️. .@Corpse_Husband why do you literally speak in bass😐. YOUR BEAUTY IS BEYOND COMPARE WITH FLAMING LOCS OF AUBURN HAIR, YOUR IVORY SKIN, AND EYES OF EMERALD GREEN🥰. all my teachers can suck my dick☺️❤️. finally blocked the person who my tweets were about☺️☺️. STREAM 8 BY BILLIE EILISH🗣‼️. SAY GERONIMO!', 'label': 0}\n"]}],"source":["from google.colab import drive\n","from datasets import load_dataset, load_metric\n","\n","drive.mount(\"/content/drive/\")\n","\n","full_dataset = load_dataset(\"csv\", data_files = path_to_data, split=\"train\", trust_remote_code=True)\n","dataset = full_dataset.train_test_split(test_size=0.1)\n","print(dataset[\"train\"][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66xXOEmlBa1Z","outputId":"15e9a71d-8cc4-4a78-efc8-dbd33302fd35"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['user_id', 'post_text', 'label'],\n","        num_rows: 1010\n","    })\n","    test: Dataset({\n","        features: ['user_id', 'post_text', 'label'],\n","        num_rows: 113\n","    })\n","})"]},"metadata":{},"execution_count":5}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272,"referenced_widgets":["812ea55d90764100881a2588108b637c","23cad358b29442e1ad8aebaba9012da7","5f697150f0fc4eaba2f639a2458cd2aa","54ae863891f0472d82b83f8f968e5b82","b55150313a35454b8994595df392a456","89deee918381468a86b012e6c144aadc","3134755ff1dc4917950154a5b40899e8","dbf1e2c2e06c47bb88f73c258053fe6c","eb4b48d063d94c2895613269ea9dba17","7e58abfb1a2a46e282f9aa1289ea8998","d80b366668944dd69577985c1f1b212b","47cfa85e4b8f41ffb29e7668a7dd0a62","6678bfe552174abf962d66ea7525c1fc","3b3748ff0fdb4e6388afe6047c41db3c","309e3de3fc5f46509442771596d76c06","37e10081eb0945c6aec170f19054b70c","5a9f04f3d3144e14ba6c80026113dadd","fa325587e6654ea0888839b36b3476ce","028a32fbf3c842a2bdc8b8157d7b8336","5af70e3fac3c46958487423b8ec05b84","3f2c8642d1764d129f3231016d95a516","dc2b6eb952a14976932955f20d6aea30","9e4398ab14ae4f38a2686729e816dd64","ddb26a53d72c40f39fea36d31eb1a51d","698070d349964569a7a72f09bb85ad69","5245bb9d39da4162a14ce847a1d35ed8","98b7f1294fca478b8402303c9d1398ab","da0862b19e0b44849ac0cbdb1d741a09","00274491a64f4956bfaa1058d6051081","b34ae2c1221b465cb1cfad893886f3d4","412928c299b04dfc81adc8e035a01dbf","1349db7a3fb54b39af16b4c3a9824293","197f8668928e45abb0f7fe51352fd6a9","2a8e2c6e56854e7aa6ba446b613b469f","27141d43e07e4e4c96dd5a6100fe6aaf","df7bda734afd469f876220d971c28dac","d021300b660c4b2bbf30bcb7d46ddb7f","b0cc90915309448bb9f90eb71b940164","84cb3205744b4d89bd57210b8ef859b3","f265c4067fcd44af85cd9dd163518acf","680f91e93c094c0cbfa4ecc7fb4ec5e7","061ca1fad93547a08ec672774bcccc6c","f56882d788b54989a4352064686c9a13","d7ed8e4118214309a0c68b29272c998d"]},"id":"xquxdoaB-eMA","outputId":"75ac31e6-923c-4afb-928e-508af784a530"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"812ea55d90764100881a2588108b637c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47cfa85e4b8f41ffb29e7668a7dd0a62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4398ab14ae4f38a2686729e816dd64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a8e2c6e56854e7aa6ba446b613b469f"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260,"referenced_widgets":["ccf75c8cffbb432695d51bc91b9b4992","3893a77b81bc4582b39124a2a4134208","019ad89021dc42f0b002457caa570f7e","1c559761321c47129c4144d472a8ee34","b70d92fda84f4d508c7793737a418df6","02e61e3423ad4ca98fcb34a554d20aa3","f529968feb6b462db6214dacec0f5df9","81fd1238b4994a3dabcf703f28e1a75a","dbca41f4373e4ac48c511ce7c8042314","37a9e28a6b4b4a0781c9e648c0741b5e","2f6d5bb3e89d43a5ad26b9e9eaef04a0","931dd53114454c2ea64833c54dcff3e6","386d7378de194f7eaa2527796cc03151","e3adc5a5876a419fa53ffa68d82b1a0c","89298651537f45b9833e63fc838ab36e","a3f7b881dfaa442a8cbb2be47a6a8e21","a5bd31a61c59468b8d3349830eb8fec6","84ae6513e61d4d2d9f4e0a1549a46744","e7f7376e9d7e4ffc917e080bd6f63cb1","74166fca30284c7ab35e045799b041e4","5941003cd99b4f6c96ca38deed3b7817","5e3438af17654ede8869605b64ed9bd4"]},"id":"RYcA_2aq9p6I","outputId":"5c18655d-8f7f-4e6b-b651-8b373b00dc84"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1010 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccf75c8cffbb432695d51bc91b9b4992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/113 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"931dd53114454c2ea64833c54dcff3e6"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['user_id', 'post_text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 1010\n","    })\n","    test: Dataset({\n","        features: ['user_id', 'post_text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 113\n","    })\n","})"]},"metadata":{},"execution_count":7}],"source":["def preprocess_fn(examples):\n","    return tokenizer(examples[\"post_text\"], truncation = True)\n","\n","encoded_dataset = dataset.map(preprocess_fn, batched = True)\n","encoded_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLf3OmfWDENo"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","args = TrainingArguments(\n","    repo_name,\n","    eval_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate = 6.780781971197275e-05,\n","    per_device_train_batch_size = 4,\n","    per_device_eval_batch_size = 16,\n","    num_train_epochs = 4,\n","    weight_decay = 0.05,\n","    load_best_model_at_end = True,\n","    metric_for_best_model = \"accuracy\",\n","    push_to_hub = False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cB1jLXo-HnK0","outputId":"51bbe7a3-f677-4957-9680-edb5bf35db06"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["import numpy as np\n","\n","metric = load_metric(\"accuracy\", trust_remote_code = True)\n","\n","def compute_metrics(eval_pred):\n","    preds, labels = eval_pred\n","    preds = np.argmax(preds, axis = 1)\n","    return metric.compute(predictions = preds, references = labels)\n","\n","def model_init():\n","    return AutoModelForSequenceClassification.from_pretrained(base_model, num_labels = 2)\n","\n","\n","trainer = Trainer(\n","    model_init=model_init,\n","    args=args,\n","    train_dataset = encoded_dataset[\"train\"].shard(index = 1, num_shards = 10),\n","    eval_dataset = encoded_dataset[\"test\"],\n","    tokenizer = tokenizer,\n","    compute_metrics = compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"T6tXJxhgJoA6","outputId":"3c17beaa-09d7-450c-ba36-c67acbea79f6"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:22:05,446] A new study created in memory with name: no-name-d4719e14-b4bf-42d3-8c6c-f60135387ada\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8/8 00:13, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.760988</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.710453</td>\n","      <td>0.407080</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:22:23,356] Trial 0 finished with value: 0.40707964601769914 and parameters: {'learning_rate': 8.449706849507742e-05, 'num_train_epochs': 2, 'seed': 14, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.40707964601769914.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [21/21 00:20, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.879027</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.808834</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.758562</td>\n","      <td>0.407080</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:22:45,481] Trial 1 finished with value: 0.40707964601769914 and parameters: {'learning_rate': 1.6221451008103506e-05, 'num_train_epochs': 3, 'seed': 29, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.40707964601769914.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [104/104 00:27, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.694323</td>\n","      <td>0.601770</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.693224</td>\n","      <td>0.460177</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.772167</td>\n","      <td>0.415929</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.682250</td>\n","      <td>0.592920</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:23:13,710] Trial 2 finished with value: 0.5929203539823009 and parameters: {'learning_rate': 6.780781971197275e-05, 'num_train_epochs': 4, 'seed': 22, 'per_device_train_batch_size': 4}. Best is trial 2 with value: 0.5929203539823009.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4/4 00:13, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.730228</td>\n","      <td>0.415929</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.945399</td>\n","      <td>0.398230</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:23:29,407] Trial 3 finished with value: 0.39823008849557523 and parameters: {'learning_rate': 7.427086456098073e-05, 'num_train_epochs': 2, 'seed': 21, 'per_device_train_batch_size': 64}. Best is trial 2 with value: 0.5929203539823009.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [26/26 00:08, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.704232</td>\n","      <td>0.398230</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:23:38,830] Trial 4 finished with value: 0.39823008849557523 and parameters: {'learning_rate': 1.2167864525323417e-06, 'num_train_epochs': 1, 'seed': 12, 'per_device_train_batch_size': 4}. Best is trial 2 with value: 0.5929203539823009.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='26' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [26/78 00:03 < 00:06, 7.50 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.712195</td>\n","      <td>0.398230</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:23:43,315] Trial 5 pruned. \n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [20/20 00:28, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.799660</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.739951</td>\n","      <td>0.407080</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.713282</td>\n","      <td>0.442478</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.696826</td>\n","      <td>0.486726</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.693456</td>\n","      <td>0.495575</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:24:13,086] Trial 6 finished with value: 0.49557522123893805 and parameters: {'learning_rate': 1.0557313628263575e-05, 'num_train_epochs': 5, 'seed': 30, 'per_device_train_batch_size': 32}. Best is trial 2 with value: 0.5929203539823009.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [35/35 00:29, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.713313</td>\n","      <td>0.415929</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.732924</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.745435</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.754313</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.755592</td>\n","      <td>0.398230</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:24:44,450] Trial 7 finished with value: 0.39823008849557523 and parameters: {'learning_rate': 2.0953531338286036e-06, 'num_train_epochs': 5, 'seed': 27, 'per_device_train_batch_size': 16}. Best is trial 2 with value: 0.5929203539823009.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8/8 00:09, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.838182</td>\n","      <td>0.398230</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.745499</td>\n","      <td>0.398230</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-08-02 05:24:55,349] Trial 8 pruned. \n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/6 00:00 < 00:01, 1.51 it/s, Epoch 1/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.805012</td>\n","      <td>0.407080</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[W 2024-08-02 05:24:59,155] Trial 9 failed with parameters: {'learning_rate': 1.9185267410476043e-05, 'num_train_epochs': 3, 'seed': 9, 'per_device_train_batch_size': 64} because of the following error: TypeError(\"unsupported operand type(s) for /: 'int' and 'NoneType'\").\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\", line 211, in _objective\n","    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1932, in train\n","    return inner_training_loop(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2365, in _inner_training_loop\n","    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2793, in _maybe_log_save_evaluate\n","    metrics = self._evaluate(trial, ignore_keys_for_eval)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2751, in _evaluate\n","    self._report_to_hp_search(trial, self.state.global_step, metrics)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1545, in _report_to_hp_search\n","    self.callback_handler.on_train_end(self.args, self.state, self.control)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\", line 464, in on_train_end\n","    return self.call_event(\"on_train_end\", args, state, control)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\", line 508, in call_event\n","    result = getattr(callback, event)(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/notebook.py\", line 373, in on_train_end\n","    self.training_tracker.update(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/notebook.py\", line 161, in update\n","    self.update_bar(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/notebook.py\", line 183, in update_bar\n","    self.label += f\", {1/self.average_time_per_item:.2f} it/s\"\n","TypeError: unsupported operand type(s) for /: 'int' and 'NoneType'\n","[W 2024-08-02 05:24:59,157] Trial 9 failed with value None.\n"]},{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for /: 'int' and 'NoneType'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e47bbc570dc4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameter_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   3204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_objective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_compute_objective\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompute_objective\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcompute_objective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m         \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/hyperparameter_search.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_hp_search_optuna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault_hp_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdirections\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_multi_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36m_objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;31m# If there hasn't been any evaluation during the training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2791\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2793\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2750\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2751\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m         \u001b[0;31m# Run delayed LR scheduler now that metrics are populated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_report_to_hp_search\u001b[0;34m(self, trial, step, metrics)\u001b[0m\n\u001b[1;32m   1543\u001b[0m                 \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_prune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1546\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHPSearchBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_train_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    509\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/notebook.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         self.training_tracker.update(\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {int(state.epoch)}/{state.num_train_epochs}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/notebook.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, value, force_update, comment)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_time_per_item\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_remaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_time_per_item\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/notebook.py\u001b[0m in \u001b[0;36mupdate_bar\u001b[0;34m(self, value, comment)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\", +inf it/s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\", {1/self.average_time_per_item:.2f} it/s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"]\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mf\", {self.comment}]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'int' and 'NoneType'"]}],"source":["best_run = trainer.hyperparameter_search(n_trials = 10, direction = \"maximize\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"2AXhxUbzKFNI","outputId":"4935318b-3dc7-4243-c555-f8ad9ecb90ce"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'best_run' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-736d2c86382e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'best_run' is not defined"]}],"source":["best_run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJAW5H45KGKs"},"outputs":[],"source":["for n, v in best_run.hyperparameters.items():\n","    setattr(trainer.args, n, v)\n","trainer.train_dataset = encoded_dataset[\"train\"]\n","# setattr(trainer.args, \"num_train_epochs\", 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":292},"id":"oG5-d_8wIoZm","outputId":"c876243c-f291-4b91-87b7-5646d41e0c1d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at AIMH/mental-bert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [104/104 00:27, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.665087</td>\n","      <td>0.610619</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.910256</td>\n","      <td>0.407080</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.927886</td>\n","      <td>0.522124</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.928410</td>\n","      <td>0.628319</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=104, training_loss=0.5761726819551908, metrics={'train_runtime': 27.4002, 'train_samples_per_second': 14.744, 'train_steps_per_second': 3.796, 'total_flos': 106296866365440.0, 'train_loss': 0.5761726819551908, 'epoch': 4.0})"]},"metadata":{},"execution_count":14}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"26wzJvcjIpab","outputId":"31889e4e-b04a-492b-8a98-6c0189ff80c6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.6675335764884949,\n"," 'eval_accuracy': 0.6415,\n"," 'eval_runtime': 2.7347,\n"," 'eval_samples_per_second': 731.33,\n"," 'eval_steps_per_second': 45.708,\n"," 'epoch': 4.0}"]},"metadata":{},"execution_count":14}],"source":["trainer.evaluate()"]},{"cell_type":"code","source":["trainer.push_to_hub()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["18d4a4e7bed2477e891b04e8c6294ad5","e27183fc2a064551b1f977e1a8c009aa","b9b62c72f4ae4ccf93eb19fd7e8e4834","8a286a8ecd5c4914a6d4e0428cd922e8","4dbafc78d3d44dd4939d4979dc3fab29","ca98d6f1591f4b05bcefec0d9bab9177","257b2391621d42b59c6c742dc9f66f8a","ef7d708968034c528f3e53a493f87731","9205298e62274566b7f717e95e4b470b","c22bae9aa81348bd821be23f99878120","e84cfc9c74a44c888c742aa6af131f09"]},"id":"noNDiSJDFNuZ","outputId":"c9158b44-072e-4d84-8021-4792f21e9481"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["events.out.tfevents.1722570954.8953887c6028.7787.11:   0%|          | 0.00/411 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d4a4e7bed2477e891b04e8c6294ad5"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/Silicon23/BERTForDetectingDepression-Twitter2020-baseBERT/commit/309cad4dae5e2ca74ff41fa7f6df00d07cf047ed', commit_message='End of training', commit_description='', oid='309cad4dae5e2ca74ff41fa7f6df00d07cf047ed', pr_url=None, pr_revision=None, pr_num=None)"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]}]}